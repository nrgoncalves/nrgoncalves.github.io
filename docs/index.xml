<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Nuno Gonçalves</title>
    <link>https://nrgoncalves.github.io/</link>
    <description>Recent content on Nuno Gonçalves</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Wed, 29 Apr 2020 12:54:15 +0100</lastBuildDate><atom:link href="https://nrgoncalves.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Privacy-compatible automated contact tracing</title>
      <link>https://nrgoncalves.github.io/posts/cx/</link>
      <pubDate>Wed, 29 Apr 2020 12:54:15 +0100</pubDate>
      
      <guid>https://nrgoncalves.github.io/posts/cx/</guid>
      <description>If you are following the news, you may have heard about Contact Tracing and how it can help us contain communicable diseases such as COVID-19. Essentially, contact tracing is the process of manually identifying and closely monitoring those in close contact with people that have been diagnosed with an infectious disease. It is commonly performed for diseases such as tuberculosis and measles and it can help by:
Breaking transmission chains Notifying contacts of a potential infection Enabling early testing and treatment of vulnerable contacts However, the large volumes of COVID-19 cases and the speed at which the disease spreads make it difficult to perform accurate and timely contact tracing manually.</description>
    </item>
    
    <item>
      <title>A normalization model of multisensory integration</title>
      <link>https://nrgoncalves.github.io/posts/normalization-msi/</link>
      <pubDate>Mon, 14 Nov 2016 12:54:15 +0100</pubDate>
      
      <guid>https://nrgoncalves.github.io/posts/normalization-msi/</guid>
      <description>Many neurons in the brain are driven by more than one sensory system (e.g. vision and audition), and they might play an important role in improving our perception of what surrounds us. Here I explore recent work by Ohshiro and colleages on the role of divisive normalization in multisensory integration.
Take a look at the notebook here.</description>
    </item>
    
    <item>
      <title>Adapting the disparity energy model to natural stimuli</title>
      <link>https://nrgoncalves.github.io/posts/dem-natural/</link>
      <pubDate>Sat, 01 Oct 2016 12:54:15 +0100</pubDate>
      
      <guid>https://nrgoncalves.github.io/posts/dem-natural/</guid>
      <description>A short notebook on the disparity energy model and responses to correlated and anticorrelated binocular images.
Take a look at the notebook here.</description>
    </item>
    
    <item>
      <title>Marr and Poggio&#39;s cooperative stereo algorithm</title>
      <link>https://nrgoncalves.github.io/posts/marr-poggio/</link>
      <pubDate>Sat, 01 Oct 2016 12:54:15 +0100</pubDate>
      
      <guid>https://nrgoncalves.github.io/posts/marr-poggio/</guid>
      <description>David Marr was a bright computer scientist whose work still has a remarkable impact in modern computational neuroscience. He published several papers on stereoscopic vision, of which the most popular I explore here.
Take a look at the notebook here.</description>
    </item>
    
    <item>
      <title>A brief demo of the classical disparity energy model</title>
      <link>https://nrgoncalves.github.io/posts/dem-julia/</link>
      <pubDate>Mon, 14 Sep 2015 12:54:15 +0100</pubDate>
      
      <guid>https://nrgoncalves.github.io/posts/dem-julia/</guid>
      <description>Nearly a quarter of a century has passed since Ohzawa and colleagues proposed a model of how cortical neurons in primary visual cortex might support depth discrimination. Here is a demo of how it works, written in Julia.
Take a look at the notebook here.</description>
    </item>
    
  </channel>
</rss>
