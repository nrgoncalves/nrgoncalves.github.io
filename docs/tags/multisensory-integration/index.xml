<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Multisensory integration on Nuno Gonçalves</title>
    <link>https://nrgoncalves.github.io/tags/multisensory-integration/</link>
    <description>Recent content in Multisensory integration on Nuno Gonçalves</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Mon, 14 Nov 2016 12:54:15 +0100</lastBuildDate><atom:link href="https://nrgoncalves.github.io/tags/multisensory-integration/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A normalization model of multisensory integration</title>
      <link>https://nrgoncalves.github.io/posts/normalization-msi/</link>
      <pubDate>Mon, 14 Nov 2016 12:54:15 +0100</pubDate>
      
      <guid>https://nrgoncalves.github.io/posts/normalization-msi/</guid>
      <description>Many neurons in the brain are driven by more than one sensory system (e.g. vision and audition), and they might play an important role in improving our perception of what surrounds us. Here I explore recent work by Ohshiro and colleages on the role of divisive normalization in multisensory integration.
Take a look at the notebook here.</description>
    </item>
    
  </channel>
</rss>
