<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Setting up a Spark Standalone Cluster | Nuno Gonçalves</title>
<meta name="keywords" content="Spark, PySpark">
<meta name="description" content="This is a quick note on how to set up a Spark cluster in standalone mode. This is useful if you want to setup a cluster for your own development purposes or if you just want to do it for fun—for more serious use cases, Spark clusters should be setup on top of YARN or Kubernetes.
You will need to create a few VMs: one VM for the cluster manager and then one or more VMs where the executors will be running.">
<meta name="author" content="">
<link rel="canonical" href="https://nrgoncalves.github.io/posts/spark-standalone-cluster/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.d7fb4cbf980fe688a21621b06a795933c4e6bb2d4070ec940667af1715d84af2.css" integrity="sha256-1/tMv5gP5oiiFiGwanlZM8Tmuy1AcOyUBmevFxXYSvI=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://nrgoncalves.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://nrgoncalves.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://nrgoncalves.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://nrgoncalves.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://nrgoncalves.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Setting up a Spark Standalone Cluster" />
<meta property="og:description" content="This is a quick note on how to set up a Spark cluster in standalone mode. This is useful if you want to setup a cluster for your own development purposes or if you just want to do it for fun—for more serious use cases, Spark clusters should be setup on top of YARN or Kubernetes.
You will need to create a few VMs: one VM for the cluster manager and then one or more VMs where the executors will be running." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://nrgoncalves.github.io/posts/spark-standalone-cluster/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-14T15:09:12&#43;01:00" />
<meta property="article:modified_time" content="2022-07-14T15:09:12&#43;01:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Setting up a Spark Standalone Cluster"/>
<meta name="twitter:description" content="This is a quick note on how to set up a Spark cluster in standalone mode. This is useful if you want to setup a cluster for your own development purposes or if you just want to do it for fun—for more serious use cases, Spark clusters should be setup on top of YARN or Kubernetes.
You will need to create a few VMs: one VM for the cluster manager and then one or more VMs where the executors will be running."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://nrgoncalves.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Setting up a Spark Standalone Cluster",
      "item": "https://nrgoncalves.github.io/posts/spark-standalone-cluster/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Setting up a Spark Standalone Cluster",
  "name": "Setting up a Spark Standalone Cluster",
  "description": "This is a quick note on how to set up a Spark cluster in standalone mode. This is useful if you want to setup a cluster for your own development purposes or if you just want to do it for fun—for more serious use cases, Spark clusters should be setup on top of YARN or Kubernetes.\nYou will need to create a few VMs: one VM for the cluster manager and then one or more VMs where the executors will be running.",
  "keywords": [
    "Spark", "PySpark"
  ],
  "articleBody": "This is a quick note on how to set up a Spark cluster in standalone mode. This is useful if you want to setup a cluster for your own development purposes or if you just want to do it for fun—for more serious use cases, Spark clusters should be setup on top of YARN or Kubernetes.\nYou will need to create a few VMs: one VM for the cluster manager and then one or more VMs where the executors will be running. For instance:\nmanager.myproject.example.com node01.myproject.example.com node02.myproject.example.com Note: this setup would be better done via a configuration management tool such as Puppet, mainly to make it really easy to add new nodes to the cluster. I’ve written a very quick intro to setting up Puppet here. However, we will be doing this manually here as it might not be worth the overhead of setting up Puppet.\nFirst, we need to install Spark. Here I am using Debian 11 but Spark should work regardless of the OS provided that Java is installed. Let’s do the following on all VMs:\n# Install Java, if not installed sudo apt install default-jre # Install Spark (note: pick a recent version here) wget https://downloads.apache.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz tar xvf spark-3.3.0-bin-hadoop3.tgz sudo mv spark-3.3.0-bin-hadoop3 /opt/spark Then we need to add the following variables to .profile:\nexport SPARK_HOME=/opt/spark export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin export PYSPARK_PYTHON=/usr/bin/python3 and source .profile to get those variables set.\nOn the master node, generate an SSH key pair to allow the master to communicate with the workers via SSH\n# Generate an ssh key pair ssh-keygen -t rsa Then add the id_rsa.pub public key to each of the nodes .ssh/authorized_keys file. Finally, return to the master node to configure Spark:\n# Spark configuration cp $SPARK_HOME/conf/spark-env.sh.template $SPARK_HOME/conf/spark-env.sh cp $SPARK_HOME/conf/workers.template $SPARK_HOME/conf/workers # Get the path to java (value of java.home) from java -XshowSettings:properties -version # Add java home and master host to spark-env.sh # export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 # export SPARK_MASTER_HOST=manager.myproject.example.com sudo nano $SPARK_HOME/conf/spark-env.sh # Add the worker hosts to the workers file # i.e. node01.myproject.example.com, node02.myproject.example.com, one in each line sudo nano $SPARK_HOME/conf/workers # Start the cluster $SPARK_HOME/sbin/start-all.sh # Verify that the worker exists by fetching the Spark UI page curl http://127.0.0.1:8080/ That is it—the Spark cluster is now ready! You may now want to setup an SSH tunnel to allow you to access the master VM conveniently from your local desktop environment.\n",
  "wordCount" : "391",
  "inLanguage": "en",
  "datePublished": "2022-07-14T15:09:12+01:00",
  "dateModified": "2022-07-14T15:09:12+01:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://nrgoncalves.github.io/posts/spark-standalone-cluster/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Nuno Gonçalves",
    "logo": {
      "@type": "ImageObject",
      "url": "https://nrgoncalves.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://nrgoncalves.github.io/" accesskey="h" title="Nuno Gonçalves (Alt + H)">Nuno Gonçalves</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://nrgoncalves.github.io/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://nrgoncalves.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://scholar.google.co.uk/citations?user=2xoRsiQAAAAJ&amp;hl=en" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Setting up a Spark Standalone Cluster
    </h1>
    <div class="post-meta"><span title='2022-07-14 15:09:12 +0100 BST'>July 14, 2022</span>

</div>
  </header> 
  <div class="post-content"><p>This is a quick note on how to set up a Spark cluster in standalone mode. This
is useful if you want to setup a cluster for your own development purposes or
if you just want to do it for fun—for more serious use cases, Spark clusters
should be setup on top of YARN or Kubernetes.</p>
<p>You will need to create a few VMs: one VM for the cluster manager and then
one or more VMs where the executors will be running. For instance:</p>
<ul>
<li>manager.myproject.example.com</li>
<li>node01.myproject.example.com</li>
<li>node02.myproject.example.com</li>
</ul>
<p>Note: this setup would be better done via a configuration management tool such
as Puppet, mainly to make it really easy to add new nodes to the cluster. I&rsquo;ve
written a very quick intro to setting up Puppet
<a href="https://nrgoncalves.github.io/posts/puppetserver/">here</a>. However, we will be
doing this manually here as it might not be worth the overhead of setting up
Puppet.</p>
<p>First, we need to install Spark. Here I am using Debian 11 but Spark should work
regardless of the OS provided that Java is installed. Let&rsquo;s do the following on
all VMs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Install Java, if not installed</span>
</span></span><span style="display:flex;"><span>sudo apt install default-jre
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Install Spark (note: pick a recent version here)</span>
</span></span><span style="display:flex;"><span>wget https://downloads.apache.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz
</span></span><span style="display:flex;"><span>tar xvf spark-3.3.0-bin-hadoop3.tgz
</span></span><span style="display:flex;"><span>sudo mv spark-3.3.0-bin-hadoop3 /opt/spark
</span></span></code></pre></div><p>Then we need to add the following variables to <code>.profile</code>:</p>
<pre tabindex="0"><code>export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export PYSPARK_PYTHON=/usr/bin/python3
</code></pre><p>and <code>source .profile</code> to get those variables set.</p>
<p>On the master node, generate an SSH key pair to allow the master to communicate
with the workers via SSH</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Generate an ssh key pair</span>
</span></span><span style="display:flex;"><span>ssh-keygen -t rsa
</span></span></code></pre></div><p>Then add the <code>id_rsa.pub</code> public key to each of the nodes <code>.ssh/authorized_keys</code>
file. Finally, return to the master node to configure Spark:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Spark configuration</span>
</span></span><span style="display:flex;"><span>cp $SPARK_HOME/conf/spark-env.sh.template $SPARK_HOME/conf/spark-env.sh
</span></span><span style="display:flex;"><span>cp $SPARK_HOME/conf/workers.template $SPARK_HOME/conf/workers
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get the path to java (value of java.home) from</span>
</span></span><span style="display:flex;"><span>java -XshowSettings:properties -version
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Add java home and master host to spark-env.sh</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># export SPARK_MASTER_HOST=manager.myproject.example.com</span>
</span></span><span style="display:flex;"><span>sudo nano $SPARK_HOME/conf/spark-env.sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Add the worker hosts to the workers file</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># i.e. node01.myproject.example.com, node02.myproject.example.com, one in each line</span>
</span></span><span style="display:flex;"><span>sudo nano $SPARK_HOME/conf/workers
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Start the cluster</span>
</span></span><span style="display:flex;"><span>$SPARK_HOME/sbin/start-all.sh
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Verify that the worker exists by fetching the Spark UI page</span>
</span></span><span style="display:flex;"><span>curl http://127.0.0.1:8080/
</span></span></code></pre></div><p>That is it—the Spark cluster is now ready! You may now want to setup an SSH
tunnel to allow you to access the master VM conveniently from your local desktop
environment.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://nrgoncalves.github.io/tags/spark/">Spark</a></li>
      <li><a href="https://nrgoncalves.github.io/tags/pyspark/">PySpark</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://nrgoncalves.github.io/">Nuno Gonçalves</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
